{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa45f58-b5a5-4ef5-9926-e1599a09f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path as path\n",
    "import gzip\n",
    "from typing import Dict, List, Tuple, AnyStr, KeysView, Any\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ecc279-5722-41ab-8823-641c6088ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'data/MNIST/raw/'\n",
    "files_name = {\n",
    "    'train_img': 'train-images-idx3-ubyte.gz',\n",
    "    'train_label': 'train-labels-idx1-ubyte.gz',\n",
    "    'vali_img': 't10k-images-idx3-ubyte.gz',\n",
    "    'vali_label': 't10k-labels-idx1-ubyte.gz'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2077c41c-b6f4-4020-bfe1-d0ac5a82e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(files_name) -> Tuple:\n",
    "    with gzip.open(path.join(dataset_folder, files_name['train_img']), mode='rb') as data:\n",
    "        train_img = torch.frombuffer(data.read(), dtype=torch.uint8, offset=16).reshape(-1, 1, 28, 28)\n",
    "    # 加载训练集 标签\n",
    "    with gzip.open(path.join(dataset_folder, files_name['train_label']), mode='rb') as label:\n",
    "        train_label = torch.frombuffer(label.read(), dtype=torch.uint8, offset=8)\n",
    "    # 加载验证集 图片\n",
    "    with gzip.open(path.join(dataset_folder, files_name['vali_img']), mode='rb') as data:\n",
    "        test_img = torch.frombuffer(data.read(), dtype=torch.uint8, offset=16).reshape(-1, 1, 28, 28)\n",
    "    # 加载验证集 label\n",
    "    with gzip.open(path.join(dataset_folder, files_name['vali_label']), mode='rb') as label:\n",
    "        test_label = torch.frombuffer(label.read(), dtype=torch.uint8, offset=8)\n",
    "    return (train_img, train_label),(test_img, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59393280-6df8-44f2-bd55-defc96682f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30399\\AppData\\Local\\Temp\\ipykernel_28744\\1813352808.py:3: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:1550.)\n",
      "  train_img = torch.frombuffer(data.read(), dtype=torch.uint8, offset=16).reshape(-1, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MNIST_dataset(Dataset):\n",
    "    def __init__(self, data: List, label: List):\n",
    "        self.__data = data\n",
    "        self.__label = label\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if not item < self.__len__():\n",
    "            return f'Error, index {item} is out of range'\n",
    "        return self.__data[item], self.__label[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__data)\n",
    "# 读取数据\n",
    "train_data,test_data = dataloader(files_name)\n",
    "# 将数据封装为 MNIST 类\n",
    "train_dataset = MNIST_dataset(*train_data)\n",
    "test_dataset = MNIST_dataset(*test_data)\n",
    "len(train_dataset), len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa26689-186b-427d-aea4-d87c07c16d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5))\n",
    "        self.conv1 = nn.Conv2d(6, 16, kernel_size=(5, 5))\n",
    "        self.pool0 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 2))\n",
    "        self.linear0 = nn.Linear(16*4*4, 120)\n",
    "        self.linear1 = nn.Linear(120, 84)\n",
    "        self.linear2 = nn.Linear(84, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, x):\n",
    "        output = self.conv0(x)\n",
    "        output = self.pool0(output)\n",
    "        output = self.conv1(output)\n",
    "        output = self.pool1(output)\n",
    "        output = self.flatten(output)\n",
    "        output = self.linear0(output)\n",
    "        output = self.relu(output)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        output = self.linear1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "\n",
    "net = NetWork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626c5779-5efe-48f9-acc0-b87de049a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, loss, train_iter, test_iter, optimizer, epochs, device):\n",
    "    net = net.to(device)\n",
    "    epoch_losses = []\n",
    "    train_correct = 0\n",
    "    train_len = 0\n",
    "    test_correct = 0\n",
    "    test_len = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        epoch_losses.clear()\n",
    "        for img, label in train_iter:\n",
    "            img, label = img.to(device, dtype=torch.float), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(img)\n",
    "            l = loss(output, label)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            epoch_losses.append(l.item())\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            train_correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "            train_len += len(label)\n",
    "\n",
    "        train_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        train_acc = train_correct / train_len * 100.0\n",
    "        print(f'-----------epoch: {epoch + 1} start --------------')\n",
    "        print(f'epoch: {epoch} train loss: {train_loss}')\n",
    "        print(f'epoch: {epoch} train acc: {train_acc}')\n",
    "\n",
    "        # validation\n",
    "        epoch_losses.clear()\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for img, label in test_iter:\n",
    "                img, label = img.to(device, dtype=torch.float), label.to(device)\n",
    "                test_output = net(img)\n",
    "                l = loss(test_output, label)\n",
    "                epoch_losses.append(l.item())\n",
    "                test_pred = test_output.argmax(dim=1, keepdim=True)\n",
    "                test_correct += (test_pred.squeeze() == label).sum().item()\n",
    "                test_len += len(label)\n",
    "\n",
    "            test_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "            test_acc = test_correct / test_len * 100.0\n",
    "            print(f'epoch: {epoch} test loss: {test_loss}')\n",
    "            print(f'epoch: {epoch} test acc: {test_acc}')\n",
    "            print(f'-----------epoch: {epoch + 1} end --------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6604ab9b-5b07-4e55-9de9-27183e301fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------epoch: 1 start --------------\n",
      "epoch: 0 train loss: 0.5704973290729336\n",
      "epoch: 0 train acc: 79.73833333333333\n",
      "epoch: 0 test loss: 0.47110058530736715\n",
      "epoch: 0 test acc: 83.52000000000001\n",
      "-----------epoch: 1 end --------------\n",
      "-----------epoch: 2 start --------------\n",
      "epoch: 1 train loss: 0.37574759227796456\n",
      "epoch: 1 train acc: 83.11416666666666\n",
      "epoch: 1 test loss: 0.4022045310129411\n",
      "epoch: 1 test acc: 84.65\n",
      "-----------epoch: 2 end --------------\n",
      "-----------epoch: 3 start --------------\n",
      "epoch: 2 train loss: 0.35645316969580015\n",
      "epoch: 2 train acc: 84.43611111111112\n",
      "epoch: 2 test loss: 0.37681149199898356\n",
      "epoch: 2 test acc: 85.26\n",
      "-----------epoch: 3 end --------------\n",
      "-----------epoch: 4 start --------------\n",
      "epoch: 3 train loss: 0.3452461419521289\n",
      "epoch: 3 train acc: 85.17083333333333\n",
      "epoch: 3 test loss: 0.3853519351546769\n",
      "epoch: 3 test acc: 85.545\n",
      "-----------epoch: 4 end --------------\n",
      "-----------epoch: 5 start --------------\n",
      "epoch: 4 train loss: 0.29592213014059937\n",
      "epoch: 4 train acc: 86.07433333333333\n",
      "epoch: 4 test loss: 0.24126474381538282\n",
      "epoch: 4 test acc: 87.398\n",
      "-----------epoch: 5 end --------------\n",
      "-----------epoch: 6 start --------------\n",
      "epoch: 5 train loss: 0.12589710699404047\n",
      "epoch: 5 train acc: 87.87027777777779\n",
      "epoch: 5 test loss: 0.18725210876795637\n",
      "epoch: 5 test acc: 88.81166666666667\n",
      "-----------epoch: 6 end --------------\n",
      "-----------epoch: 7 start --------------\n",
      "epoch: 6 train loss: 0.11679572501040633\n",
      "epoch: 6 train acc: 89.16238095238094\n",
      "epoch: 6 test loss: 0.19783642910696717\n",
      "epoch: 6 test acc: 89.74\n",
      "-----------epoch: 7 end --------------\n",
      "-----------epoch: 8 start --------------\n",
      "epoch: 7 train loss: 0.11175541727236356\n",
      "epoch: 7 train acc: 90.15875\n",
      "epoch: 7 test loss: 0.16456801923295844\n",
      "epoch: 7 test acc: 90.525\n",
      "-----------epoch: 8 end --------------\n",
      "-----------epoch: 9 start --------------\n",
      "epoch: 8 train loss: 0.10698532392489506\n",
      "epoch: 8 train acc: 90.94444444444446\n",
      "epoch: 8 test loss: 0.1933866436937031\n",
      "epoch: 8 test acc: 91.12777777777778\n",
      "-----------epoch: 9 end --------------\n",
      "-----------epoch: 10 start --------------\n",
      "epoch: 9 train loss: 0.10595051961465381\n",
      "epoch: 9 train acc: 91.58699999999999\n",
      "epoch: 9 test loss: 0.17904221595456674\n",
      "epoch: 9 test acc: 91.606\n",
      "-----------epoch: 10 end --------------\n"
     ]
    }
   ],
   "source": [
    "net = NetWork()\n",
    "batch_size = 16\n",
    "train_iter = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_iter = DataLoader(test_dataset, batch_size=batch_size)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "num_epoch = 10\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "train(net, loss, train_iter, test_iter, optimizer, num_epoch, device)# from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b609f-b4f7-4b96-b353-bbca5708d077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
